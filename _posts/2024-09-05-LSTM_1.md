---
title:  "LSTM 이론 1탄"
---



순전파 학습
-----------------

### LSTM모델이 RNN모델과 다른 점이 뭘까?

RNN모델과 비교했을 때 셀 상태와 세 개의 gate(forget gate, input gate, output gate)가 추가되었다.

### 그러면 셀 상태가 추가되고 세 개의 gate가 추가된 이유가 뭘까?

RNN모델에서 발생하는 기울기 소실 문제를 해결하기 위함이다.

### LSTM모델구조를 알아보자

![image](https://github.com/user-attachments/assets/2db721c9-361e-4824-8e3e-efd2ebf936aa)

그림에서 보듯이 cell state(c_t)와 세 개의 gate(forget gate, input gate, output gate)가 추가된 것을 알 수 있다.

### 일단 세 개의 gate에 대해서 자세히 알아보자.
세 개의 gate는 병렬적으로 처리되지만 forget gate, input gate, output gate 순으로 진행된다.

#### 1. forget gate

![image](https://github.com/user-attachments/assets/dea9eb76-de3c-4160-92c6-ce2beb2a2b30)

forget gate는 말그대로 이전상태의 셀에서 나온 값을 얼마나 가져갈 것인가를 결정합니다.

![image](https://github.com/user-attachments/assets/fd226715-aba2-4f16-adaa-c5b5521091a1)

그림에서 보듯이 이전 은닉 상태와 현재 입력값을 기반으로 시그모이드 함수에 의해서 0~1사이의 값이 생성된다. 
이는 이전 상태의 셀(c_t-1)중에 얼마나 가져가야할 것인지를 결정한다고 볼 수 있다.

#### 2. input gate

![image](https://github.com/user-attachments/assets/02470901-c75e-45a2-b7ac-86e21ae58811)

input gate는 새로운 셀 상태에 얼마만큼의 정보(input)을 넣을 건지 결정하는 gate이다. 앞에서 말했다시피 순차적으로 진행되기 때문에 forget gate에서 나온 c_t에 얼마만큼의 정보를 넣을 건지 결정한다고 생각하면 된다.

##### 그러면 얼마만큼의 정보를 넣을 건지 결정하는 과정에 대해서 살펴보자.
1. 첫번째로 기억 셀을 생성한다.

![image](https://github.com/user-attachments/assets/636fa3f9-1a12-40d8-805a-d75acb5fdffc)

![image](https://github.com/user-attachments/assets/f6b21b05-e899-430b-880d-1470d1e0f82f)

2. 그림에서 보듯이 h_t-1와 x_t를 기반으로 새로운 정보와 관련한 셀을 생성한다.

![image](https://github.com/user-attachments/assets/b20ab553-7ec4-4dad-93eb-c698591969a4)

![image](https://github.com/user-attachments/assets/39669427-5562-4117-aa6c-f387276b9977)

![image](https://github.com/user-attachments/assets/7efc8a1d-281b-4dcf-9494-9c6be8645448)


3. 이후에 기억 셀에서 어느 정도를 추가해줄 것인지 비율을 생성한다.이때 i와 g간의 아다마르곱을 수행한다. 아다마르곱은 행렬간의 연산방법 중에 행렬의 각 성분에 대해 같은 위치에 있는 성분끼리 곱해주는 연산을 말한다.

#### 3. output gate

![image](https://github.com/user-attachments/assets/1a3f533e-5f9b-4b4e-b9d3-dbe3264f234a)

output gate는 forget gate와 input gate를 거친 새로운 셀 상태(c_t) 중에 어느 정도를 새로운 은닉상태(h_t)에 부여할 것인지를 결정하는 gate라고 볼 수 있다.

![image](https://github.com/user-attachments/assets/015e7f8d-1fe7-4ff0-af1a-81bdc1b4204c)

그림에서 보듯이 h_t-1와 x_t를 기반으로 어느정도의 비율을 은닉상태로 전달한 것인지를 결정한다.


역전파 학습
--------

#### 1. slice node이전까지의 역전파 과정
![image](https://github.com/user-attachments/assets/a33ac6d0-180e-41b4-af27-c5604f9ec912)

1. h_t가 두군데로 흘러가는 것을 확인할 수 있는데 하나는 새로운 은닉상태로 부여되고 하나는 상위 layer의 입력값으로 이동한다.
2. 특정 상태의 값 앞에 d가 붙어있는데 이는 특정 상태에 대해 편미분했다는 의미이다. 예를 들어 dh_t는 h_t에 대해서 미분했다는 의미이다.
3. 위 그림은 각각의 gate(f, g, i, o)에 대해 미분한 값까지 어떻게 이동하는지를 의미한다.

### 다음에는 기울기 소실 문제를 어떻게 해결했는지 그리고 slice node이후의 역전파 과정에 대해 알아보자.





