---
layout: post
title:  "Association Rule Mining 1탄"
---

## 1. 정의

추천시스템의 일종으로 X를 선택했을 때 어떤 y를 추천할 것인가
여기서 아이템의 수량은 고려하지 않음

예시)

|transaction_id|Bread|Milk|Cola|Zzanggu|
|---|---|---|---|---|
|1|1|0|0|1|
|2|1|1|1|1|
|3|0|0|0|1|
|4|1|1|0|0|

주의 사항 : 

1. x와 y의 인과관계를 찾아내는 것이 아님. x와 y간의 연관관계가 있다는 의미.
2. x와 y는 각각 하나의 집합으로 표현 가능. 예시) x={라면,김밥} y={콜라,김치}
3. x와 y간의 교집합이 공집합이여야한다. 예시) x={라면,김밥}  y = {김치,라면} (x)

## 2. 연관규칙을 만드는데 필요한 지표

### 1. 지지도(support)

특정 아이템이 얼마나 구매되었는가를 판단 = P(X)

|transaction_id|Bread|Milk|Cola|Zzanggu|
|---|---|---|---|---|
|1|1|0|0|1|
|2|1|1|1|1|
|3|0|0|0|1|
|4|1|1|0|0|

예를 들어 bread라고 하면 3/4 = 0.75에 해당한다.

### 2. 신뢰도(confidence)

특정 아이템을 구매했을 때 어떤 아이템을 구매할 확률(즉, 특정 아이템(X)을 구매했을 때의 구매내역을 모두 보고난 뒤에 그 중에서 어떤 아이템(Y)를 얼마나 구매했는가)

|transaction_id|Bread|Milk|Cola|Zzanggu|
|---|---|---|---|---|
|1|1|0|0|1|
|2|1|1|1|1|
|3|0|0|0|1|
|4|1|1|0|0|
|5|1|1|1|0|

예를 들어 Bread를 구매했을 때 milk를 구매할 확률은 bread를 구매한 경우가 총 4번이고 그 중에 milk를 3번 구매했으므로 신뢰도(confidence)=0.75이다.

### 3. lift

아이템 집합 x와 아이템 집합 y간의 상관관계를 의미. 즉, x와 y가 독립이라고 가정했을 때에 비하여 얼마만큼의 연관관계가 있는가.

$$ 
lift = P(X,Y)/P(X)*P(Y)
$$

P(X,Y) = P(X)*P(Y)인 경우 X와 Y가 독립이라는 의미이므로 lift=1일 경우 X와 Y간의 상관관계 없다고 판단

P(X,Y) > P(X)*P(Y)인 경우 X와 Y가 양의 상관관계가 있다는 의미

P(X,Y) < P(X)*P(Y)인 경우 X와 Y가 음의 상관관계가 있다는 의미

#### lift를 지표로 사용하는 이유가 뭘까?

confidence가 1이더라도 Y가 기본 아이템이라서 항상 고객들이 사는 아이템이라면 confidence가 1이 나올 수가 있다. 그래서 lift를 통해서 P(Y)를 계산하게 되면 Y가 등장한 횟수가 반영되기 때문에
이를 고려하여 산출할 수 있다.

## 사용되는 알고리즘

#### A Priori Algorithm

모든 아이템들 중에서 각각의 아이템에 대하여 support와 특정 기준을 비교했을 때 넘지 못하면 그 아이템을 포함하는 모든 아이템 집합들은 연관규칙을 찾는데 고려되지 않는다.

좀 더 자세히 표현하자면 아이템 집합의 갯수가 1개일 때 support를 계산하여 기준이 0.7이라고 했을 때 0.7을 넘는 아이템들을 연관규칙에 쓴다. 그리고 그러한 아이템들로 원소 갯수가 2개인 집합으로 다시 support를
계산하여 0.7이상인 집합을 다시 추린다. 이러한 방식으로 0.7을 넘는 집합이 나오지 않을 때까지 원소 갯수를 늘려나간다.

이후 confidence를 기준으로 앞서 추린 집합들 중에서 다시 추린다.

이후 lift를 계산하여 상황에 따라 support, confidence, lift 중에 중요하다고 생각하는 요소를 선정하고 이를 기준으로 연관규칙을 찾아낸다.


##### 다음 주에는 apriori algrithm이 무엇인지 알아보고 이중에 적용할만한 요소가 있는지 찾아봐야겠다.


